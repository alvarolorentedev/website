---
published: '2024-04-04T00:00:00.000Z'
canonical_url: https://leadshorizons.com/p/ai-in-the-workplace
series: Engineering Strategy 101
authors:
  - alvarolorentedev
description: >-
  Explore the potential and pitfalls of Large Language Models (LLMs) in the
  workplace. This comprehensive guide discusses the hype surrounding AI and
  LLMs, their psychological appeal, and practical applications in user-facing
  products, company tools, and work augmentation. Learn about the quality and
  licensing issues in coding with LLMs, and understand their impact on
  productivity and code quality. The article also highlights the importance of
  ethical decision-making in technology advancement.
Tags:
  - productivity
  - technology
  - startup
  - development
cover_image: >-
  https://prod-files-secure.s3.us-west-2.amazonaws.com/df75203e-cd58-41eb-8339-d5bf4288eb0e/5695fb01-7665-42a8-9ec5-5f3400222df3/bearly-generated-image-PCT6BW.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=ASIAZI2LB4662U5SVOED%2F20250220%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20250220T120439Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEJT%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJIMEYCIQC5d5qGY4GZbxzD23A%2Fb%2FPLOWS%2BNFpcYXElq%2FHkUl%2FMKwIhAIzuVLrrtYDSKSJGyLRrEj15xiE2mMkw%2BoT%2B5XHYvW%2FVKogECL3%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQABoMNjM3NDIzMTgzODA1IgyUjMR2lA62LPbublAq3APRJuh1S2vBigV7KWbPafiDNMJmt5lpH9RBRtUJ96d42%2FPgv3v6H9LHC872JkUCY8TbOeclRBoJvT1xIr%2F79PivRvWgD0mL%2FxKCrkXMF1inrGPQjL8LE7tA4TeaJUcN80kupVvpsVAzzODhyPqaztEyy4Jov2f21AD2EXm1jNsMKLcPKUidrRuy2HKfawYxeT3%2FspDqegYO9ZYXeMI4%2FsL7VPou7mbj140f6%2Bbna%2BgS87687XkTJOHj9oGFcbBsJ1vkuOP7EwU9hMVJMK1rDf3XsP4j%2Fc%2F8nJ6s9KJVs71Pq8eQeqJ9aW4%2B30jdRHlqWOWxzfOHFtGaLRUau1crK7H7hVXVucasnenpk8RTxpDCNqKcAs0uc4tC0t5KEO%2B2r0ccgS8Sopzqrt3MJUmTdVYQrWEwDJZwcxKdEUkwtjaz3fi%2BU9rrFR8brp44RvL3SXCy4De7TGbHdy3tG2fKy6Mn09iOgPjcAw%2BzJa1AToBIJSO30X2ctO1ZxSXXQ%2F7zjoKbJUf6iuV6jTZA0wklwHV9j4ydMGo5c%2Fseq%2BRmurSQKAl2g%2FQKrZcNiJ%2BaSFL1TA09Ka%2Bzfkp5pjiA%2F4Fk9Z9o%2BQyKi%2B8BEb8%2Bkmp%2FutWIhWZGb%2FzuBRm8I1Iz3zD%2FrNy9BjqkAf5BNxPuHDDN9F0vWg4M%2BdIVQq78lPgIpJsTBMEU8qhtNYJrEeawFcIyVTFXK6pg%2Fg1cMd3hLa5YZ1Ke%2FxiaAcyOINGYrancEpu6sAI6K0E5oVw2kerGrzuyUsb9X0nME5NHVKqsVRL7VtDl2V0T6BR%2B67MI7uwsIzW%2Fl2EDdJP8Fjfcz08aNUXr31IuED7YYxvySdhl9atFLiSPms92ldTEhrh0&X-Amz-Signature=2fee55d5795836555e01a69a9b950dfd02532ad0be52f7e6ff2306ed641e290f&X-Amz-SignedHeaders=host&x-id=GetObject
title: 'AI In The Workplace: Are LLMs Hype or Reality?'
---

This past year, the buzz word in technology has undeniably been "AI". But what exactly do we mean when we say AI?


Often, our comprehension of terms and definitions can be clouded due to the ambiguity in the language used. A prime example is the term "Artificial Intelligence" (AI). This term used to encompass a broad spectrum of technologies, but recently, it has become largely associated with Large Language Models (LLMs).


## What are we talking about?


AI, in its purest form, is the ability of a machine or computer program to think and learn. It is the theory and development of computer systems able to perform tasks that typically require human intelligence. 


Meanwhile, LLMs are defined in this [Wikipedia article](https://en.wikipedia.org/wiki/Large_language_model) as: 


> A language model notable for its ability to achieve general-purpose language generation and other natural language processing tasks such as classification. LLMs acquire these abilities by learning statistical relationships from text documents during a computationally intensive self-supervised and semi-supervised training process.[1] LLMs can be used for text generation, a form of generative AI, by taking an input text and repeatedly predicting the next token or word


It goes without saying that we have yet to reach the real definition of AI, with neither LLMs nor other technologies.


## The Psychology of LLMs Hype


What has made these large language models so intriguing over the past year, prompting such widespread interest?


Their ability to “bullshiting with confidence”. Just try this out yourself, ask any question to an LLM and just tell them they are mistaken and request another option. You'll typically receive an apology followed by an assertive, alternative response.


![llm1.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/df75203e-cd58-41eb-8339-d5bf4288eb0e/702b745b-8e9a-437c-a8ee-92063ef1b0c2/llm1.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=ASIAZI2LB4666FOSF4FW%2F20250220%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20250220T120440Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEJT%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIQChK2VvZmnWtKp15ay8xt%2FEfyZXlo0RMQT4nxJCUEnnvgIgZ%2FX0qzvhJdLKKadefI6klb%2FoegobvhIf8vJF3CLgiVYqiAQIvf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw2Mzc0MjMxODM4MDUiDBDz2iHZAzl7mGg0mircA%2B8eHyZcxP3ZR75%2B%2ByUq%2FhQuDaCjnc%2FJgxv18F9YvfcJuft1qjF9RtLgPzr1z3BRxV2NUYdkkISMfRHHfFhIhcK09H8aERHuuJO8nL0dYYlKFnTWmfje1m61abJN%2BygwxCqEQgqGnLKm%2FAeXEPb80QnArhaauQxwEDH7p3rttyeu%2FIOty00%2FD2h%2Fd0x7C9cNYtmo0xdn23%2FS6fF8yWfCKToCGaoZc3MflEM3QUBFPA5fK9ukEM4zpBn1dIKdpMikPWLtdOvjAnJNzB5vXR9nyS04mvY69otlH7dUralsx4JonS6qdBGU5XfnJWHiQVvqAvasMbk4HVc0hz9qYOADgI5nn8ECKCWApCO9m2CPi6Pe4grYbOenVi12ZOErcDBYZPcvwISy08fBKPdXK2Y9Rl6u6JxLam11T0EpzTZm%2FkoAOHLzQm%2Fagha297MzhAvUVE4jVlZx5odYPnWBD4PJ3IsYQyRyiSXEsI147mCyw8%2FZfmmELA0YNUdfVfrMqXRoN6QBveQG1%2FU85i3HQDjaJyxzMdeFlyOxgiVkbm0aT%2BPXyylDUG2EstcG9SWejYpoBYPDf%2FUrMZWGKGpumxEY4TIQ8NpAgn5qNJZbC4YpFtO3qD4FjOhPR1Je4HcvMIGt3L0GOqUBm33QLgv%2FFDLdGCu63nzFgPnjU%2BPEojlsDkXgDp1IwQ%2B1H9ZRfL%2BbdeXPa8EeAdIanwXcLFG8Uw1q9kR5t3Kowfq3U9C%2FVg1r%2Byh%2FL8dTJHY0cd9SQnTWZgC1OKorOjq%2BX5EBQjqbD0COFtPmpm1tZ7JTVtqJgpDB2MiRKMzxLUmGAImb4k4Y%2BMCguR0CMzYDzy4Jw7SlnRip%2F5XrHXHBlGyGg6%2BT&X-Amz-Signature=78d2e246df09efe55c4cbbfd1509b906066d5d2b5ddc7cd056a5b93b4aa02668&X-Amz-SignedHeaders=host&x-id=GetObject)


To clarify, these software models aren't intentionally deceptive. They simply aim to provide responses that align with your queries. Meanwhile, we as recipients are prone to accept information as accurate, especially when it's delivered with apparent confidence. This applies to both machine-generated responses and human communication. Even this paragraph, written by a non-psychologist, likely seems plausible because it's framed convincingly.


So how does an LLM “bullshiting with confidence”. LLMs are trained to recognize patterns in data and make predictions based on these patterns. Essentially, they are statistical functions that predict, given the words in a question, the words that will form a compelling response. This phenomenon of non-accurate but compelling responses goes by the name of [hallucinations](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)).


## LLMs at the Workplace


Are LLMs useless? Not at all. Despite the caution required due to the nature of statistically generated responses, these systems can indeed provide substantial value.


Let's explore potential applications:


### User-Facing Products


Interestingly, this technology might just be the first to convince humans they're interacting with another human or an intelligent entity. This opens up new product opportunities where the perceived "human interface" might have more value than the precise accuracy of the content.


Potential applications could include:

- First-tier customer support: By integrating LLMs with user manuals, we could develop a chatbot interface for customers.
- Sales representatives: LLMs could be utilized to create more human-like, machine-driven robot calls or chatbots.

Does this mean human roles will be totally replaced? No, because LLMs lack a true understanding of the problem or the conversation. Therefore, a second level of human intervention remains essential. However, this technology could help businesses scale their operations in a novel way.


> ⚠️ Personally, I would not use the current technology for products that require accuracy. (example: tax calculations, finances, etc.).


### Company Tools 


Typically, businesses possess an extensive amount of data that encapsulates their knowledge base. Filtering this data can be challenging, especially when it's scattered across various systems, making it tough to query. Leveraging LLMs can significantly streamline this process and reduce the mental strain of pinpointing the required information.


> ⚠️ Keep in mind, LLMs do normally not provide precise responses. Thus, it's crucial to critically assess the answers and cross-reference with the original data for accuracy.


### Work Augmentation


This tool has a wide range of applications that can be incorporated into daily workflows. Let's explore some common utilization.


**Writing Assistance**


LLMs can provide valuable support in crafting documents, emails, and other written communications. They offer grammatically correct and contextually fitting sentence suggestions, enhancing the overall writing process.


As a general rule, this is a highly productive use of the technology. Just ensure to review the generated suggestions for maximum benefit.


**Reference Tool**


LLMs can serve as a dynamic reference resource, drawing on the vast expanse of knowledge they've been trained on. They function like a sophisticated search engine, delivering consolidated information.


> ⚠️ However, as LLMs may not always provide accurate responses, it's crucial to approach the information critically and cross-check with original data sources when necessary.


**Coding**


Within the realm of coding, LLMs can help in code generation and even in writing documentation. This is possibly the field that can affect most of the readers of this newsletter, so let's do a deep dive on this point.


From my professional experience, we've opted not to utilize this technology so far. The main factors influencing this decision include:

- Quality Inheritance: The quality of code that LLMs generate is directly linked to the quality of the training data. If the model is trained on data that includes poor or flawed code, the generated code will inherit those flaws.
- Cognitive Load: While LLMs can simplify routine coding processes, they can also increase the cognitive burden on developers who need to review and comprehend the generated code, ensuring it meets expectations. Developers may face a choice of accepting the code as-is with potential issues or spend additional time deciphering the proposed code.
- Licensing: Employing LLMs may lead to potential breaches of software licenses. If the model is trained on code under copyleft licenses (e.g., GPL), the generated code could be seen as derivative, thus resulting in licensing complications.

Additionally, upon reviewing the data accumulated over the duration this technology has been in existence, we can observe the following results:

- Supporting Data:
	- Microsoft Experiment: The results were that developers using copilot were able to complete the task 55.8% faster.
	- Pinterest  Experiment ([Link](https://www.youtube.com/watch?v=70Rc4wJRluA&t=1032s)):  They found that their engineers who commit code less often increased their commit rate by 50-100%, and engineers who commit code the most often became about ~40% more productive.
- Detracting Data:
	- Git Clear Research ([Link](https://www.gitclear.com/coding_on_copilot_data_shows_ais_downward_pressure_on_code_quality)): analyzed approximately 153 million changed lines of code, they found code churn (the percentage of lines that are reverted or updated less than two weeks after being authored) is projected to double in 2024 compared to its 2021, pre-AI baseline.
	- Security Researchers ([Link](https://www.theregister.com/2021/08/25/github_copilot_study/)): Explored Copilot's performance on three distinct code generation axes (examining how it performs given diversity of weaknesses, diversity of prompts, and diversity of domains). In total, we produce 89 different scenarios for Copilot to complete, producing 1,689 programs. Of these, we found approximately 40% to be vulnerable.

> ⚠️ While the technology shows promise, it's not fully developed yet.  
> Our studies indicate that while short-term productivity may increase, this comes at the expense of code quality. This aligns with the concerns we initially discussed.


	Our studies indicate that while short-term productivity may increase, this comes at the expense of code quality. This aligns with the concerns we initially discussed.


As we conclude this article, it's important to highlight the potential vulnerabilities associated with Large Language Models (LLMs) in the workplace. I strongly recommend familiarizing yourself with potential threats and reading more about this topic via the [OWASP TOP 10 for LLMs](https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-2023-slides-v1_0.pdf) resource.


## Conclusion


The term "Artificial Intelligence" (AI) has recently become synonymous with Large Language Models (LLMs). However, true AI, the ability of a machine to think and learn, has not been achieved with LLMs or other technologies. 

LLMs have gained popularity due to their ability to generate convincing responses, but these responses are merely statistical predictions based on input data. Despite this, LLMs can be valuable in the workplace, serving as user-facing products, company tools, and work augmentation. However, caution is advised due to their lack of accuracy. 


Lastly, it's imperative that we bear in mind our social responsibility as creators and innovators in the realm of technology. With the current global population standing at 8.1 billion, each decision we make, each technological advancement we introduce, has the potential to impact a vast number of lives. We should, therefore, strive to prioritize the wellbeing of each individual in this global community, ensuring that our contributions to technology are both ethical and beneficial to all.

